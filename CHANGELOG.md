# Changelog

## [Unreleased]

### 2026-02-27
- **feat:** Zero-downtime blue-green container updates — `UpdatePod` now pre-extracts the new image in a throwaway staging container while the old container continues serving traffic, then performs a fast cutover (~5-8s) that skips tarball extraction entirely (RouterOS skips extraction when root-dir already has content). Staging container is health-checked before cutover; on failure, old container remains untouched and falls back to destructive update. Alternating root-dir pattern avoids naming conflicts across successive updates. Reduces update downtime from 120s+ to ~5-8s for all mkube-managed containers.
- **feat:** ISO9660 binary patching — derive ISCSICdroms by copying and patching ISOs at the binary level. New `pkg/provider/iso9660.go` implements PVD parsing, directory record parsing with Rock Ridge NM support, path resolution, and file read/replace/delete/add operations. No external tools (xorriso, mkisofs) required. New API endpoints: `GET /api/v1/iscsi-cdroms/{name}/files?path=...` reads files or lists directories from ISOs, `POST /api/v1/iscsi-cdroms/{name}/derive` creates a new ISCSICdrom by copying the base ISO, applying patch operations (replace/delete/add files), and configuring a new iSCSI target. `ISCSICdromSpec.DerivedFrom` tracks the base ISO lineage. Enables baking serial console and iBFT kernel args into ISO grub.cfg for iPXE sanboot.

### 2026-02-27
- **fix:** Registry HTTP/2 GOAWAY crash — disabled HTTP/2 on registry server (TLSNextProto). Go's h2 implementation sends GOAWAY during large blob uploads, killing the registry process. HTTP/1.1 is sufficient for internal use.
- **feat:** Registry panic recovery middleware — all registry HTTP handlers wrapped with `recover()`. A single request panic no longer crashes the entire registry process; instead logs the stack trace and returns 500.
- **feat:** Infrastructure health check — mkube reconcile loop now checks registry.gt.lo health via HTTP GET to `:5001/healthz` every 10s. After 3 consecutive failures, automatically restarts the container via RouterOS API. Catches zombie state where RouterOS shows RUNNING but process is dead.
- **fix:** mkube-update poll interval default changed from 60s to 15s. Installer template and code default both updated.
- **feat:** BootConfig CRD — cluster-scoped resource for managing boot configuration templates (ignition, cloud-init, kickstart, custom). Full CRUD API at `/api/v1/bootconfigs/{name}` with watch support, table format. Source IP lookup endpoint at `GET /api/v1/bootconfig` (singular) — servers fetch their config during PXE boot by source IP → BMH match → bootConfigRef → data content. Content-Type auto-set by format (ignition JSON, cloud-init YAML, kickstart plain text). BMHSpec extended with `bootConfigRef` field. BootConfig status tracks `assignedTo` BMH list (auto-synced on BMH create/update/patch/delete). Delete protected (409 if BMHs reference it). Consistency checks verify memory↔NATS sync and assignedTo validity. NATS JetStream persistence in BOOTCONFIGS bucket. Both immediate and deferred boot paths load from store.
- **docs:** Updated README with complete API reference for all resource types (Networks, PVCs, BMH, iSCSI CDROMs, ConfigMaps, Registries, Events). Added oc/kubectl commands section with resource table, short names, and common usage examples.
- **feat:** Added `scripts/setup-iscsi-cdrom.sh` helper — creates iSCSI CDROM, uploads ISO, cleans up previous CDROM with same name (unsubscribes all, deletes with ISO cleanup). Tested 10/10 passes.
- **fix:** mkube-update tarball format — replaced `crane.Save` (OCI format: compressed layers, no repositories file, no VERSION/json per layer) with custom `saveRouterOSTarball` that produces the exact docker-save v1 format RouterOS expects. Matches `hack/make-tarball.sh` structure: `manifest.json`, `repositories`, `{configHash}.json`, `{layerHash}/layer.tar` (uncompressed), `{layerHash}/VERSION`, `{layerHash}/json`. Verified end-to-end: mkube-update successfully detects digest change, pulls image, creates correct 43MB tarball, and replaces mkube container.
- **feat:** mkube-update GHCR fallback — when local registry pull fails, automatically falls back to `ghcr.io/glennswest/{repo}:{tag}`.
- **fix:** mkube-update scratch container /tmp — `os.CreateTemp` defaults to /tmp which doesn't exist in scratch containers. Now uses the staging directory for temp files.
- **fix:** mkube-update bootstrap retry — REST API may not be reachable immediately after container start. Bootstrap now retries 5 times with 3s backoff before concluding mkube doesn't exist, preventing false bootstraps that fail with "root-dir overlap".
- **fix:** iSCSI CDROM uses ROSE /disk API — RouterOS doesn't have `/iscsi` REST path. Rewrote iSCSI integration to use `/disk/add type=file` + `/disk/set iscsi-export=yes`. RouterOS auto-generates IQN from slot name. Verified end-to-end: create, upload ISO, iSCSI export enabled, subscribe, unsubscribe, delete with cleanup.
- **fix:** gw DNS server address — was 192.168.1.199 (unreachable), corrected to 192.168.1.52 (pvex CT 117). Removed gw.lo from forward zones temporarily (external DNS sync deferred).
- **fix:** Registry TLS cert mismatch — installer regenerated CA+server certs on re-run but registry container wasn't restarted, causing ECDSA verification failure when mkube tried to pull images. Root cause: stale certs from previous installer run being served.

### 2026-02-26
- **feat:** iSCSI CDROM CRD — cluster-scoped resource for sharing ISO images via RouterOS native iSCSI. Full CRUD API at `/api/v1/iscsi-cdroms/{name}` with watch support, table format for `oc get icd`. ISO upload via multipart POST to `/upload` subresource. Subscribe/unsubscribe endpoints track active consumers. RouterOS iSCSI target and LUN auto-created on upload, auto-removed on delete. Delete protected (409 if subscribers exist). Consistency checks verify memory↔NATS sync and ISO file existence. Export/import support in YAML multi-doc. NATS JetStream persistence in ISCSICDROMS bucket. Both immediate and deferred boot paths load from store.
- **fix:** BMH create handler now defaults IPMI credentials to ADMIN/ADMIN when BMC address is set. Update handler preserves existing credentials when the PUT body omits them, preventing credential loss.
- **fix:** Registry CRD migration now runs when `registry.enabled=false` but `localAddresses` is configured (standalone registry). Also added `LoadRegistriesFromStore`/`MigrateRegistryConfig` to the immediate NATS boot path in `cmd/mkube/main.go`.
- **feat:** Registry CRD — cluster-scoped dynamic registry definitions stored in NATS JetStream. Full CRUD API at `/api/v1/registries/{name}` with watch support, table format for `oc get registries`, config generation via `/api/v1/registries/{name}/config`. Managed registries auto-deploy pod + ConfigMap on create and auto-teardown on delete. Managed transitions handled on update/patch (false→true deploys, true→false tears down, config changes update ConfigMap). One-time migration from `config.yaml` RegistryConfig on first boot (default registry, managed=false — installer owns it). Consistency checks verify memory↔NATS sync and HTTP /v2/ liveness per registry. Export/import support in YAML multi-doc.
- **feat:** Auto-deploy microdns on Network CRD create — when a Network is created with `managed: true` and DNS zone/server configured, mkube automatically creates a dns-config ConfigMap (generated TOML) and deploys a microdns pod with startup/liveness/readiness probes, static IP, image-policy auto, and config/data volume mounts. On network delete, the managed DNS pod and ConfigMap are auto-removed before the pod-reference check. Update/patch transitions (managed false→true, true→false, config changes while managed) are handled. Pod creation goes through the ContainerRuntime interface — works on RouterOS, StormBase, or any future backend.
- **feat:** BMH → Network CRD DHCP reservation sync — when a BareMetalHost is created, updated, or deleted, its DHCP reservation is automatically synced to the referenced Network CRD. Supports both data network (boot MAC, data IP, PXE settings) and IPMI network (IPMI MAC, IPMI IP, IPMI hostname) independently. Per-reservation PXE fields (`next_server`, `boot_file`, `boot_file_efi`) emitted in generated microdns TOML config. Existing config-migrated reservations are preserved (upsert by MAC only).
- **feat:** BMHSpec extended with network and PXE fields — `network`, `ip`, `hostname`, `nextServer`, `bootFile`, `bootFileEfi` for the data interface. BMCDetails extended with `mac`, `hostname`, `network` for the IPMI interface. Network column added to `oc get bmh` table output.
- **fix:** Network PATCH handler now merges instead of replacing — was wiping all fields not included in the patch body. Uses DeepCopy + json.Unmarshal merge pattern.
- **chore:** Cleaned up 19 old duplicate BMH objects from g10/g11 namespaces (pxemanager-discovered entries superseded by proper default namespace BMHs with network fields).
- **fix:** Cross-namespace BMH dedup in DHCP watcher — subnet scanner and DHCP lease processor were creating duplicate BMH objects in network namespaces (e.g. `g11/server1`) when a proper BMH already existed in `default` namespace. Now checks all existing BMHs by boot MAC, BMC MAC, and hostname before creating discovered entries.
- **feat:** Per-server BMH consistency checks — each physical server's BMH is validated: data network reference exists with matching DHCP reservation (by boot MAC), IPMI network reference exists with matching reservation (by BMC MAC). Duplicate detection flags same boot MAC, BMC MAC, or hostname appearing on multiple BMH objects. Memory↔NATS sync verified.
- **fix:** PVCs and Deployments not loaded from NATS on boot — `LoadPVCsFromStore` and `LoadDeploymentsFromStore` were only called in the deferred NATS path (`SetStore`), not in the immediate boot path. PVCs vanished on every restart. Now both are loaded regardless of NATS connection timing.
- **fix:** DHCP watcher only creates BMH from IPMI networks — data network MACs can never trigger auto-discovery. Prevents spurious BMH objects from known server NICs on data networks.
- **fix:** DHCP watcher checks existing DHCP reservations before creating BMH — MACs already reserved in any Network CRD are skipped (known NICs, not new hosts).
- **fix:** Namespaced BMH list uses network join — `/namespaces/g10/baremetalhosts` returns all physical servers referencing g10 via any field (data network, IPMI network, or metadata namespace). One entry per server regardless of how many networks it's on.
- **fix:** mkube-update rolling update stuck on missing container — `gw_dns_microdns` (external DNS on pvex) was first in the microdns targets list, causing "not found" error that broke the entire rollout every poll cycle. Removed gw from targets. Also changed rolling update to skip missing containers instead of aborting the whole rollout.
- **fix:** Container replace root-dir overlap recovery — after removing a container, RouterOS may still hold the root-dir lock. `replaceContainer` now waits for the container to be truly gone, then retries create up to 5 times on "root-dir overlap" errors with 3s backoff.
- **feat:** Network CRD — cluster-scoped dynamic network definitions stored in NATS JetStream. Full CRUD API at `/api/v1/networks/{name}` with watch support, table format for `oc get networks`, delete protection (409 if pods reference the network). Generates microdns TOML config via `/api/v1/networks/{name}/config` endpoint. One-time migration from `config.yaml` NetworkDef entries on first boot. Consistency checks verify memory↔NATS sync and DNS liveness per managed network. Export/import support in YAML multi-doc.
- **feat:** PersistentVolumeClaim (PVC) support — persistent volumes that survive container recreation, image updates, and pod deletes. PVC-backed volumes live under `/raid1/volumes/pvc/{namespace}_{claimName}` and bypass the ephemeral ProvisionVolume/GC path. Full CRUD API at `/api/v1/namespaces/{ns}/persistentvolumeclaims`. Watch support, table format for `oc get pvc`, consistency checks (memory↔NATS sync, pod→PVC reference validation), export/import in YAML multi-doc. Delete protection: 409 Conflict if PVC is referenced by a pod. Optional `?purge=true` to remove on-disk directory.

### 2026-02-25
- **fix:** Staggered container restarts — containers sharing the same image are now restarted one at a time with liveness verification between each. Prevents simultaneous outages (e.g., all three DNS pods going down at once during an image update). Applied to: reconciler image update (step 3c), boot-time stale image check, `POST /images/redeploy`, deployment rolling updates, and DNS liveness repair. Each pod is verified alive (container running + DNS port 53 probe for DNS pods) before the next is restarted. Rollout halts on liveness failure.

### 2026-02-24
- **fix:** DNS port 53 liveness probe — consistency check now sends an actual DNS query to port 53 on each managed DNS server. Detects the case where the microdns container is running (REST API up on 8080) but the recursor on port 53 has crashed or failed to start. Auto-restarts the DNS pod when port 53 is dead. Root cause: all three microdns instances (gt, g10, g11) restarted simultaneously with recursor silently failing to bind port 53 — REST API and auth DNS (15353) survived but the actual resolver was dead for hours undetected.
- **fix:** Add retry with backoff to container start — MikroTik REST API returns EOF when previous container hasn't fully torn down. Both `CreatePod` and `replaceContainer` (rolling update) now retry up to 7 times with 2-5s backoff, re-fetching container ID between attempts.
- **fix:** Increase veth name truncation from 8 to 15 characters — prevents collisions for pods with shared name prefixes in the same namespace (e.g. `fastregistry` and `fastregistry-replica`).
- **feat:** Deployment controller — new lightweight Deployment resource that manages pod replicas with auto-recreation on delete, scale up/down, rolling image updates, and DNS round-robin load balancing. Deployment-owned pods survive deletion (recreated within 10s by reconciler). CRUD API at `/api/v1/namespaces/{ns}/deployments`. Persisted in NATS JetStream. Consistency checks verify replica counts. Export/import support included.
- **feat:** Tarball-based container updates — mkube-update now pre-pulls images as docker-save tarballs from registry while old container is still running, then swaps using `file=` parameter instead of `remote-image`. Eliminates the chicken-and-egg problem where registry can't pull its own update. Works for all containers: registry, mkube, microdns, etc. New config fields `tarballDir` and `tarballROSPath`.
- **fix:** Registry concurrency — replaced global RWMutex in BlobStore with per-resource locking. Blob reads are lock-free (immutable content-addressed). Blob writes use per-digest mutex. Manifest operations use per-repo RWMutex. Upload sessions use per-session mutex. Different repos/blobs can now be pushed/pulled concurrently.
- **fix:** Registry operation timeouts — added 15s timeout to `getRegistryDigest` and 2min timeout to `pullAndUpload` in storage manager. Prevents reconcile loop from blocking indefinitely when registry is unresponsive.
- **fix:** Handle orphaned pods in NATS during delete — `GetPod` now falls back to NATS store when pod isn't tracked in memory. `handleDeletePod` can delete orphaned pods (e.g., `infra/registry`) that exist in NATS but never got tracked because `CreatePod` failed. Cleaned stale `infra/registry` entry from NATS.
- **feat:** `boot_file_efi` support for UEFI PXE boot — new `bootFileEfi` field in `DHCPConfig`, TOML generation in `buildDHCPSection()`. g10 serves `ipxe.efi` to UEFI clients.
- **fix:** Add server30 DHCP reservations on g10 — MACs `50:6B:4B:B1:9E:26`/`27` (Mellanox 25G SFP28) → `.30`/`.31` with DNS A records.
- **fix:** Add macmini DHCP reservation on g10 — MAC `D0:11:E5:A0:1A:A4` → `.190`.
- **feat:** Extract registry into standalone container (`cmd/registry/main.go`) — solves the chicken-and-egg problem where mkube needs the registry to pull its own image. Registry now boots at priority 3 (before NATS at 5) on static IP 192.168.200.3:5000.
- **feat:** New `mkube-installer` one-shot bootstrap binary (`cmd/installer/main.go`) — creates registry container via RouterOS REST API, seeds required images from GHCR, and starts mkube-update. Automates the full first-boot sequence.
- **refactor:** Remove embedded registry from mkube — registry startup, ImageWatcher, UpstreamSyncer, and `/registry/poll` endpoint removed from `cmd/mkube/main.go`. Push events now arrive via existing `POST /api/v1/registry/push-notify` webhook.
- **feat:** Add `notifyURL` to `RegistryConfig` — standalone registry forwards push events to mkube via HTTP webhook.
- **feat:** Registry IP configurable — default `192.168.200.3`, all image refs and config updated. User can override via installer config.
- **feat:** `deploy-installer.sh` and `make-tarball-generic.sh` scripts for bootstrapping fresh devices.
- **feat:** Makefile targets: `build-registry`, `build-installer`, `build-all`, `deploy-installer`.
- **refactor:** Installer rewritten as local CLI tool (cobra) — runs on Mac, connects to device via REST API + SSH/SFTP. No tarballs, no container deployment of the installer itself.
- **feat:** Scratch-based Containerfiles for mkube, mkube-update, and mkube-registry.
- **feat:** Proper TLS for registry — installer generates CA + server cert (ECDSA P256), distributes CA cert to mkube and mkube-update. Registry serves HTTPS with fallback to HTTP.
- **fix:** Installer seeding uses separate transports for GHCR (default) and local registry (CA transport). `crane.Copy` used a single transport which broke GHCR connections when using our CA. Now uses `crane.Pull` + `crane.Push`. Adds exists-check optimization.
- **fix:** mkube-update bootstrap rewrites GHCR image refs to local registry — scratch containers have no system root CAs so GHCR TLS fails. Images are seeded by installer.
- **fix:** mkube-update bootstrap uses `remote-image` instead of tarball — RouterOS pulls directly from local registry. Removes crane/dockersave/mutate dependencies.
- **fix:** mkube-update `replaceContainer` uses `remote-image` instead of `tag` (which is read-only metadata). Adds `check-certificate=no` for RouterOS pulls.
- **fix:** IP collision between veth-mkube-update (.3) and veth-registry (.3) — mkube-update got unique IP .5. Was causing "connection refused" (container connecting to itself).
- **fix:** mkube storage manager doesn't trust standalone registry — pod specs reference old `192.168.200.2:5000` address but registry moved to `192.168.200.3:5000`. Extended `rewriteLocalhost` to detect and rewrite any non-primary local address alias (from `localAddresses` config) to the primary address. Added `192.168.200.2:5000` and `registry.gt.lo:5000` as aliases.
- **fix:** Goroutine leak in `CheckConsistencyAsync` — every call spawned a new goroutine with no deduplication. During reconcile cycles, hundreds of goroutines accumulated until OOM (exit status 2 on ARM64). Added `atomic.Bool` guard so only one consistency check runs at a time.
- **fix:** Removed registry pod from boot-order.yaml — registry is managed by mkube-installer with its own naming convention (`registry.gt.lo`, `veth-registry`), which conflicts with mkube's expected names (`infra_registry_registry`, `veth_infra_registry_0`). Caused repeated recreate failures and IP conflicts.

### 2026-02-23
- **fix:** Remove gw/dns pod from boot-order — gw microdns runs on pvex.gw.lo, not rose1. The conflicting rose1 container caused IP conflict on bridge-lan and "no route to host" errors.
- **fix:** Remove legacy dnsx.gw.lo references from all network static records — PowerDNS migration is complete, dnsx is no longer used.
- **fix:** Consistency checker DNS false positives — `checkDNS` now uses all desired pods (tracked + NATS + boot-order) instead of just boot-order manifest, and includes static records, DHCP reservations, and infrastructure records (rose1, dns) in the expected set. Eliminates false "stale" warnings for legitimate records.
- **feat:** Auto-cleanup stale DNS records — `cleanStaleDNSRecords` in async consistency checker deletes A records for unknown hostnames and removes old IPs for known hostnames (e.g., accumulated records from pod IP changes).
- **fix:** Register container-level DNS records (`container.pod` format) during reconcile — pods tracked via "already exists" path never called `AllocateInterface`, so `microdns.dns` records were missing. `reregisterPodDNS` now registers both container-level and pod-level DNS records.
- **fix:** NATS-sourced pods no longer flagged as "tracked but not in manifest" — these are deployed via `oc apply` and persisted in NATS, which is normal. Changed from warn to pass.
- **feat:** `externalDNS` flag on NetworkDef — marks networks where the DNS server is not managed by mkube (e.g., gw DNS on pvex.gw.lo). Consistency checker treats unreachable external DNS zones as pass instead of fail.
- **fix:** IPAM collision on g10/g11 — container IPAM started allocating at .2 in every subnet, colliding with static server IPs (e.g., ipmiserial getting 192.168.11.15 which is server6's IPMI). Added configurable `ipamStart`/`ipamEnd` per network in config. g10 and g11 now allocate container IPs from .200-.250, well above server reservations (.10-.30) and DHCP ranges.
- **fix:** Standalone reconciler missing digest cache clear on push events — the standalone reconciler received registry push events but did NOT call `ClearImageDigestByRepo` before reconciling, so `RefreshImage` compared stale digest vs stale digest and never detected changes. Root cause of ipmiserial (and all auto-update pods) not updating on image push.
- **feat:** `GET /api/v1/images` endpoint — exposes image cache state (refs, digests, tarball paths, pull times) for debugging auto-update issues.
- **feat:** Container network health repair — automatically detects and recreates pods with broken networking (missing veth, no IP, static IP mismatch). Tracks consecutive failures with threshold of 3 before triggering recreate to avoid flapping.
- **feat:** Static IP validation in reconcile — pods tracked via "already exists" path now have their veth IP checked against `vkube.io/static-ip` annotation. Mismatches trigger immediate delete+recreate.
- **feat:** Lifecycle failure recovery — containers that exceed max restarts are now automatically recreated with fresh veth allocation via new `OnFailed` callback from lifecycle manager.
- **feat:** Network health category in consistency report — `/api/v1/consistency` now includes a `network` section showing veth presence, IP assignment, and static IP match status for all pods.

### 2026-02-24
- **fix:** Stale image on container recreation — RouterOS skips tarball extraction when root-dir already has content from a previous container. Pods restarted via image update were running old binaries despite new tarballs being pulled. Now removes root-dir before `CreateContainer` to force fresh extraction on every creation.
- **feat:** Populate `ContainerStatus.ImageID` and `ContainerID` from storage manager digest cache and RouterOS container ID for better observability.
- **fix:** Skip external DNS networks in `InitDNSZones` and DZO Bootstrap — gw DNS runs on pvex.gw.lo (not managed by mkube). Previously, every boot and reconcile cycle tried to reach it, causing 3s timeouts per attempt (6-9s total wasted per cycle). `externalDNS: true` flag now properly respected in all DNS operations, not just the consistency checker.
- **perf:** Disk cache fallback in `EnsureImage` — on mkube restart, the in-memory image cache is empty, so EnsureImage always re-pulled from registry even when the tarball and `.digest` file were already on disk. Now checks disk `.digest` before pulling, avoiding unnecessary image pulls and reducing boot time.
- **fix:** DHCP reservation hostname — `FC:4C:EA:F9:4F:2F` was mapped to `server30` but the device identifies as `gb10`. Changed `server30`→`gb10` and `server30b`→`gb10b` in g10 DHCP reservations and DNS.
- **perf:** DNS record cache (batch mode) — `BeginBatch`/`EndBatch` on DNS client caches `ListRecords` results per zone and blacklists failed endpoints for the remainder of the batch, avoiding O(pods × containers × 2) HTTP GETs and repeated 10s timeouts during reconcile. Applied to `reregisterPodDNS`, `InitDNSZones`, and `cleanStaleDNSRecords`.
- **perf:** Reduce DNS HTTP timeout from 10s to 3s — DNS containers are local, 10s was far too generous and caused 60s reconcile cycles when namespace DNS endpoints were unreachable.
- **feat:** Boot timing instrumentation — all startup phases (`BOOT:` prefix) and reconcile steps (`RECONCILE:` prefix) now log elapsed milliseconds. Identifies bottlenecks: discovery (8.4s), DZO bootstrap (6.2s), DNS init (3.2s) = ~18s boot total. First reconcile ~188s (pod creation + DNS registration).
- **fix:** Stale DNS cleanup — when a pod gets a new IP, old A records for the same hostname are automatically removed before registering the new one. Prevents accumulation of stale DNS entries across pod recreations.
- **fix:** Root-readonly persistent mounts — root image is treated as readonly (like docker/podman). All writable data (`/raid1/cache` for tarballs+digests, `/data` for ConfigMaps) now lives on persistent mounts that survive container recreation. Prevents cascade recreation of ALL pods on mkube restart (syncConfigMapsToDisk saw missing files as "changed"). New `persistentMounts` config maps container paths to host-visible paths, replacing hardcoded `selfRootDir` translations.
- **fix:** gb10 DHCP reservation IPs — moved gb10 from `.30`/`.40` (server30's addresses) to `.50`/`.51`. gb10 is a 100gig Mellanox device, not server30 (25gig Dell).
- **fix:** DZO bootstrap stale state — persisted state had `.199` for g10/g11 DNS endpoints but actual servers are at `.252`. Bootstrap only created new entries, never updated existing ones. Now syncs IP/endpoint from config on every boot, so stale state is corrected automatically. Root cause of the 9s DZO bootstrap timeout.
- **fix:** mkube-update tag search — was hardcoded to `tag: latest` but all images use `edge`. Added `tags` field with ordered preference list (e.g. `[edge, latest]`). Searches in order, first match wins. Backward compatible with single `tag` field.
- **fix:** mkube-update bootstrap mountLists — was only `kube.gt.lo.config`, missing registry/cache/data mounts. Container recreation would lose persistent mounts.

### 2026-02-23
- **fix:** Consistency checker crash-looping containers — orphan detection only checked `p.pods` (tracked pods), not NATS store or boot-order manifest. NATS-sourced pods like ipmiserial were incorrectly flagged as orphaned and killed. Now checks all desired sources (tracked + NATS + boot-order) and skips cleanup entirely when NATS isn't connected yet.
- **fix:** Pods missing IPs after restart — IPAM not re-synced for pods tracked via "already exists" path during reconcile. Added ResyncAllocations call in reconcile and consistency checker to ensure all veths have IPAM entries
- **fix:** Auto-cleanup stale containers in CreatePod — detects and removes orphaned RouterOS containers before recreation, preventing "in use by container" veth errors
- **fix:** Force-release veths held by orphaned containers — when veth allocation fails, finds the container holding the veth, stops/removes it, and retries
- **feat:** Orphaned container detection in consistency checker — async cleanup removes RouterOS containers that follow mkube naming but aren't tracked by any pod
- **fix:** Always delete stale tarball cache and rebuild from registry — registry is the source of truth for container images
- **fix:** Clear image digest cache on registry push events — ensures immediate detection of new image pushes
- **fix:** Add persistent mount for registry blob store (`/raid1/volumes/kube.gt.lo/registry`) — data survives mkube redeploy
- **fix:** Make deploy.sh idempotent for mount creation — prevents duplicate mount entries on re-deploy
- **fix:** Paginate DNS ListRecords to find all duplicates — was only fetching first 100 records
- **feat:** Async consistency checker — runs after CreatePod, DeletePod, and reconcile to clean up orphaned veths and stale IPAM entries
- **feat:** DNS backup system — JSON exports of all microdns zones saved to `dns-backup/` for disaster recovery
- **feat:** PowerDNS migration — imported all gw.lo, g10.lo, g11.lo records + reverse zones from legacy PowerDNS (dnsx)
- **fix:** Store data volumes under `/raid1/volumes/` instead of `/raid1/images/` — prevents tarball extraction from wiping persistent data (DNS databases, etc.) on container recreation
- **fix:** Reinitialize NATS KV buckets on reconnect — prevents stale stream handles after NATS container restart
- **feat:** Add static DNS records for all zones — rose1, dns, dnsx, nats, mkube in gt/g10/g11/gw networks
- **fix:** Enable NATS monitoring port (`-m 8222`) so liveness probe works — was causing max restart failures and JetStream stream-not-found errors
- **fix:** Prevent reconciler race with image redeploy goroutine — reconciler skips pods being redeployed
- **feat:** Image auto-update: proper digest headers, stale image detection for tracked pods
- **fix:** Image update pipeline: push-triggered reconcile, robust DeletePod, orphan detection
- **feat:** Add DHCP relay support with server_ip, user=0:0, and serverNetwork routing
- **fix:** PXE boot chain: point nextServer to pxe pod and add static DNS record
- **fix:** Orphaned static IP preventing DNS container recreation
